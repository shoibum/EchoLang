# EchoLang â€“ GPUâ€‘Accelerated Multilingual Speech â†” Text â†” Speech

**English Â· à¤¹à¤¿à¤‚à¤¦à¥€ Â· à²•à²¨à³à²¨à²¡**

EchoLang is a finalâ€‘year CSE project that runs *entirely on the Appleâ€‘Silicon GPU* (Metal/MPS) and lets you:
* Transcribe speech,
* Translate it between English, Hindi, and Kannada,
* Speak the result back â€” all in one click via a Gradio web UI.

## âœ¨ Features

* **Speechâ€‘toâ€‘Text (STT)** â€” Seamless M4T recognizes 100+ languages; we expose EN Â· HI Â· KN outâ€‘ofâ€‘theâ€‘box.
* **Machine Translation** â€” IndicTransâ€‘2 yields SOTA Hindi â†” Kannada quality via English fallback.
* **Textâ€‘toâ€‘Speech (TTS)** â€” XTTSâ€‘v2 produces natural voices in all three languages.
* **Speech Translation** â€” One click: speech â†’ translated text â†’ synthesized speech.
* **Gradio Web UI** â€” Five tabs:
   1. Speech â†’ Text
   2. Text â†’ Speech
   3. Text Translation
   4. Speech â†’ Translated Text
   5. Speech â†’ Translated Speech

## ğŸ–¥ Requirements

* **macOS 13+** on Apple Silicon (Mâ€‘series) or any Linux/Windows PC with â‰¥ 8 GB RAM.
* **Python 3.11** recommended.
* **Disk**: â‰ˆ 10 GB free for models & cache.
* **Internet** only on first launch (models download once).

## ğŸ“‚ Project Layout

```
src/
 â”œâ”€ stt/
 â”‚    â”œâ”€ m4t_asr.py        # Seamless M4T ASR implementation
 â”‚    â””â”€ stt.py            # Speech-to-text interface
 â”œâ”€ translation/
 â”‚    â”œâ”€ indictrans.py     # IndicTrans-2 implementation
 â”‚    â””â”€ translator.py     # Translation interface
 â”œâ”€ tts/
 â”‚    â”œâ”€ xtts.py           # XTTS-v2 implementation
 â”‚    â””â”€ synthesizer.py    # Text-to-speech interface
 â”œâ”€ utils/
 â”‚    â”œâ”€ audio.py          # Audio processing utilities
 â”‚    â”œâ”€ model_utils.py    # Model loading/caching utilities
 â”‚    â””â”€ language.py       # Language detection and code mapping
 â”œâ”€ pipeline.py            # End-to-end pipeline implementation
 â””â”€ web/
      â”œâ”€ app.py            # Gradio web UI
      â””â”€ components.py     # UI components and layouts
models/                    # Model storage directory
requirements.txt           # Python dependencies
setup.sh                   # Setup script
reset_models.sh            # Script to reset/redownload models
```

## ğŸš€ Quick Start

1. Clone the repository:
   ```bash
   git clone https://github.com/username/echolang.git
   cd echolang
   ```

2. Run the setup script:
   ```bash
   chmod +x setup.sh
   ./setup.sh
   ```

3. Launch the application:
   ```bash
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   python -m src.web.app
   ```

4. Open your browser at http://localhost:7860

## ğŸ›  Behind the Scenes

1. **STT** â€” audio â†’ Seamless M4T encoder/decoder â†’ text (GPU).
2. **MT** â€” text â†’ IndicTransâ€‘2 translation (CPU/GPU).
3. **TTS** â€” translated text â†’ XTTSâ€‘v2 â†’ WAV (GPU).
4. **UI** â€” Gradio routes files/bytes between the three stages.

```
Speech  â”€â”
         â”œâ”€â–º 1. STT â”€â–º 2. (optional) MT â”€â–º 3. (optional) TTS â”€â–º Audio/Text out
Text    â”€â”˜
```

## ğŸ“š Model References

- Seamless M4T: [FAIR Meta AI](https://github.com/facebookresearch/fairseq/tree/main/examples/seamless_communication)
- IndicTrans2: [AI4Bharat](https://github.com/AI4Bharat/IndicTrans2)
- XTTS-v2: [Coqui TTS](https://github.com/coqui-ai/TTS)

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.